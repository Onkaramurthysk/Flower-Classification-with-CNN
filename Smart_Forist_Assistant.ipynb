{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnz_7VeI04UG"
      },
      "source": [
        "# Problem Statement: **Building a Smart Florist Assistant for AtliQ's Online Plant Store**\n",
        "\n",
        "### AtliQ is launching a new online plant and flower store aimed at making it easier for customers to select and purchase flowers. To enhance the shopping experience, AtliQ wants to implement an AI-based flower classification assistant that can identify flower types from uploaded images and provide details about them, such as availability, pricing, and care instructions. Your goal is to create and train a classification model that can accurately classify images of flowers into 102 categories using the **Oxford Flowers102 dataset**.\n",
        "\n",
        "**Pre-trained Model**: Use a model pre-trained on ImageNet (like ResNet18).\n",
        "\n",
        "**Transfer Learning Steps**:\n",
        "* Load the pre-trained ResNet18.\n",
        "* Freeze the early layers (feature extractor).\n",
        "* Replace the final classification layer with a new one for flower classification.\n",
        "* Fine-tune the model on the target dataset (Oxford Flowers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlCg5Cm61OaM"
      },
      "source": [
        "Imports and CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3Ic4vFh0R4o",
        "outputId": "3a5a788a-251f-4db8-d410-409369b5ddd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Import the required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfedWTNM1T5y"
      },
      "source": [
        "**Step1:** Dataset Overview\n",
        "\n",
        "The Oxford 102 Flowers dataset consists of 102 flower categories. Let's load the dataset and apply necessary transformations such as resizing, cropping, and normalizing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cS3JM2yZ0u5S"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 345M/345M [11:24<00:00, 504kB/s]    \n",
            "100%|██████████| 502/502 [00:00<00:00, 1.26MB/s]\n",
            "100%|██████████| 15.0k/15.0k [00:00<00:00, 11.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Define transformations for the train and validation sets\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the images to match ResNet input\n",
        "    transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n",
        "])\n",
        "\n",
        "# Download and load the training and validation datasets\n",
        "train_dataset = datasets.Flowers102(root='data', split='train', download=True, transform=transform)\n",
        "val_dataset = datasets.Flowers102(root='data', split='val', download=True, transform=transform)\n",
        "\n",
        "# Create DataLoader for batch processing\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObkJbz7z11fO"
      },
      "source": [
        "**Key Insights**:\n",
        "\n",
        "* We resize the images to 224*224 to match ResNet's input size, convert them to tensors, and normalize them using ImageNet's mean and standard deviation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzQtGbQIt8Hn"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC1EadMMuCrh"
      },
      "source": [
        "### **Step2**: Model Training without Transfer Learning (with CNNs)\n",
        "\n",
        "* Build a CNN from scratch to classify images in the Flowers 102 dataset into 102 categories using the PyTorch nn.Sequential module.\n",
        "\n",
        "**Architecture:**\n",
        "\n",
        "Two convolutional blocks:\n",
        "* Block 1: 32 filters, 3x3 kernel, ReLU, 2x2 MaxPool.\n",
        "* Block 2: 64 filters, 3x3 kernel, ReLU, 2x2 MaxPool.\n",
        "* After convolutions, the feature map size will be 64 x 56 x 56.\n",
        "*` nn.Flatten()` is used to flatten the feature maps into a vector for input to the classifier block.\n",
        "\n",
        "Classifier Block:\n",
        "* Fully connected layer with 512 neurons.\n",
        "* Dropout added with a probability of 0.5 to prevent overfitting.\n",
        "* Final fully connected layer with 102 neurons (for 102 categories) and `nn.LogSoftmax.`\n",
        "\n",
        "Use `nn.CrossEntropyLoss` as the loss function.\n",
        "\n",
        "Use `optim.Adam` as the optimizer with a learning rate of 0.0001."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZoBNWQVr3aWh"
      },
      "outputs": [],
      "source": [
        "class FlowerCNN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # First conv block\n",
        "            nn.Conv2d(3, 32, kernel_size=(3,3), padding=\"same\"),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(stride=(2,2), kernel_size=(2,2)),\n",
        "\n",
        "            # Second conv block\n",
        "            nn.Conv2d(32, 64, kernel_size=(3,3), padding=\"same\"),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(stride=(2,2), kernel_size=(2,2)),\n",
        "\n",
        "            # Flatten Layer\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        # Classifier with LogSoftmax\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(64*56*56, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  # Add dropout\n",
        "            nn.Linear(512, num_classes),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# Initialize model, criterion, and optimizer\n",
        "model_scratch = FlowerCNN().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_scratch.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AQzXlj76qe_"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROs_tWV_vCf-"
      },
      "source": [
        "**Step3**: Model Training.\n",
        "\n",
        "* num_epochs = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3umjQSGhgOp",
        "outputId": "662d05d4-f174-4186-d332-6f7d568aa2eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/8], Loss: 4.9297, Accuracy: 1.96%\n",
            "Epoch [2/8], Loss: 4.4188, Accuracy: 4.02%\n",
            "Epoch [3/8], Loss: 4.1675, Accuracy: 7.55%\n",
            "Epoch [4/8], Loss: 3.8599, Accuracy: 11.08%\n",
            "Epoch [5/8], Loss: 3.3277, Accuracy: 22.84%\n",
            "Epoch [6/8], Loss: 2.8585, Accuracy: 31.08%\n",
            "Epoch [7/8], Loss: 2.3049, Accuracy: 45.88%\n",
            "Epoch [8/8], Loss: 1.9290, Accuracy: 56.27%\n"
          ]
        }
      ],
      "source": [
        "# Training function\n",
        "def train_model_scratch(model_scratch, train_loader, loss_fn, optimizer, num_epochs=8):\n",
        "    model_scratch.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model_scratch(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = 100 * correct / total\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
        "\n",
        "# Train the model from scratch\n",
        "train_model_scratch(model_scratch, train_loader, loss_fn, optimizer, num_epochs=8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-mhZn5G4agS"
      },
      "source": [
        "**Key Insights:**\n",
        "\n",
        "* model.train() sets the model to training mode.\n",
        "\n",
        "For each batch, we:\n",
        "* Move the inputs and labels to the device (GPU or CPU).\n",
        "* Perform a forward pass to get the predictions.\n",
        "* Compute the loss using criterion.\n",
        "* Perform backpropagation with loss.backward().\n",
        "* Update the model's parameters with optimizer.step().\n",
        "* After each epoch, we calculate and print the loss and accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CuKT5ebvW26"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CFqEp7RvSKS"
      },
      "source": [
        "**Step4**: Model Evauation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErzNbgLmhtVE",
        "outputId": "138d5a7d-ae62-4399-98f5-59f25a43bba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 19.02%\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model_scratch, val_loader):\n",
        "    # Evaluation loop\n",
        "    model_scratch.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model_scratch(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "evaluate_model(model_scratch, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ1Tli40pHd0"
      },
      "source": [
        "**BONUS**: Adjust parameters and add BatchNorm/Dropout to improve the model's test accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MKcX09Fw5oe"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx9gOG59vZzB"
      },
      "source": [
        "### **Step5**: Model Training with Transfer Learning!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyKVS1Is1_2L"
      },
      "source": [
        "**Loading the Pre-Trained ResNet18 Model**\n",
        "\n",
        "We will load a pre-trained ResNet18 model and freeze all the layers except the final classification layer. This means the model will use previously learned features and only adapt the final layer for our flower classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FUyT-5tx1wuB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\chait/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [02:05<00:00, 373kB/s] \n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained ResNet18 model with proper weights specification\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Freeze all the convolutional layers (feature extractor)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the final fully connected layer (for 1000 ImageNet classes) with one for 102 flowers\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 102)\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3Lv16tT2P_7"
      },
      "source": [
        "**Key Insights:**\n",
        "\n",
        "* We load the pre-trained ResNet18 model.\n",
        "* Freeze the layers by setting param.requires_grad = False. This prevents the early layers from being updated during backpropagation.\n",
        "* Replace the final fully connected layer (model.fc) to have 102 output classes instead of 1000 (for ImageNet)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "590wRoMYi_zG"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdFXPizI2aBy"
      },
      "source": [
        "**Step6:** Setting Up the Loss Function and Optimizer\n",
        "\n",
        "Now that we have the model ready, let's set up the loss function (CrossEntropyLoss) and optimizer (Adam, lr=0.001). We'll only optimize the new fully connected layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HY45ZEUr2JYq"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer (only for the last layer)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Since we're only training the final layer, only pass its parameters to the optimizer\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmyJoaVkjBaB"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urLP7Kbb2rQS"
      },
      "source": [
        "**Step8:** Training the Model\n",
        "\n",
        "Now, let's define the training loop. We will iterate over the dataset, calculate the loss, perform backpropagation, and update the model weights for the final layer.\n",
        "\n",
        "* `num_epochs` = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7smZlhT2qqL",
        "outputId": "10bf371b-cfb1-4e42-eab4-ad931c61d4d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/6], Loss: 4.6035, Accuracy: 4.41%\n",
            "Epoch [2/6], Loss: 3.2256, Accuracy: 43.33%\n",
            "Epoch [3/6], Loss: 2.2834, Accuracy: 73.24%\n",
            "Epoch [4/6], Loss: 1.6327, Accuracy: 87.06%\n",
            "Epoch [5/6], Loss: 1.1731, Accuracy: 91.96%\n",
            "Epoch [6/6], Loss: 0.8731, Accuracy: 95.39%\n"
          ]
        }
      ],
      "source": [
        "# Training function\n",
        "def train_model(model, train_loader, loss_fn, optimizer, num_epochs=6):\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Iterate over batches\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track training loss\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Print statistics after each epoch\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = 100 * correct / total\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
        "\n",
        "# Train the model for 6 epochs\n",
        "train_model(model, train_loader, loss_fn, optimizer, num_epochs=6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drRqg88HxnWW"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMJ8JRBP3SZc"
      },
      "source": [
        "**Step9:** Evaluating the Model\n",
        "\n",
        "After training, we evaluate the model on the validation set to check how well it has learned to classify flowers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEQwmKJz2njj",
        "outputId": "2304f0ff-50ed-45e4-d221-e4f0c80ed895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 78.82%\n"
          ]
        }
      ],
      "source": [
        "# Evaluation function\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to compute gradients for validation\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Validation Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDmZmeLpjOMX"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpRp0Iu93os3"
      },
      "source": [
        "**End Result:**\n",
        "\n",
        "By using transfer learning, we leveraged a ResNet18 model pre-trained on ImageNet to classify flowers with minimal training time and data."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
